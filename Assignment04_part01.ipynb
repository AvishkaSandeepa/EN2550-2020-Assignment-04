{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 3072)\n",
      "x_test: (10000, 3072)\n",
      "y_train: (50000, 10)\n",
      "y_test: (10000, 10)\n",
      "iteration 0 / 10: loss 0.999996\n",
      "iteration 1 / 10: loss 0.957596\n",
      "iteration 2 / 10: loss 0.937864\n",
      "iteration 3 / 10: loss 0.924301\n",
      "iteration 4 / 10: loss 0.914502\n",
      "iteration 5 / 10: loss 0.906159\n",
      "iteration 6 / 10: loss 0.898421\n",
      "iteration 7 / 10: loss 0.893817\n",
      "iteration 8 / 10: loss 0.886756\n",
      "iteration 9 / 10: loss 0.881152\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regloss(y_pred,y,w1,w2=None):\n",
    "    batch_size=y_pred.shape[0]\n",
    "    loss=(1/batch_size)*(np.square(y-y_pred)).sum()+reg*(np.sum(w1*w1)+np.sum(w1*w1))\n",
    "    return loss\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "K = len(np.unique(y_train)) # Return the unique elements of a tratining output set and take it length as Classes\n",
    "Ntr = x_train.shape[0] # number of training examples\n",
    "Nte = x_test.shape[0] # number of testing examples\n",
    "Din = 3072 # By CIFAR10 data set with 32 x 32 x 3 color images\n",
    "\n",
    "# Normalize pixel values: Image data preprocessing\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0) # axis=0: mean of a column; Mean of each pixel\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K) # This function returns a matrix of binary values (either ‘1’ or ‘0’). It has number of rows equal to the length of the input vector and number of columns equal to the number of classes.\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print('x_train:', x_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "batch_size = Ntr # for gradient descent optimization batch size is equal to number of training set\n",
    "iterations = 10 # epochs\n",
    "lr = 1.4e-2 # the learning rate alpha\n",
    "lr_decay= 0.999\n",
    "reg = 5e-6 #the regularization constant - lamda\n",
    "\n",
    "\n",
    "#Ntr = x_train.shape[0]\n",
    "#Nte = x_test.shape[0]\n",
    "\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, K)\n",
    "b1 = np.zeros(K)\n",
    "\n",
    "for t in range(iterations):\n",
    "    batch_indices = np.random.choice(Ntr, batch_size)\n",
    "    x = x_train[batch_indices]\n",
    "    y = y_train[batch_indices]\n",
    "\n",
    "    #forward pass\n",
    "    y_pred=x.dot(w1)+b1\n",
    "    y_pred_test=x_test.dot(w1)+b1\n",
    "    train_loss=regloss(y_pred,y,w1)\n",
    "    test_loss=regloss(y_pred_test,y_test,w1)\n",
    "    loss=(1/batch_size)*(np.square(y-y_pred)).sum() + reg*(np.sum(w1*w1))\n",
    "    loss_history.append(train_loss)\n",
    "        \n",
    "        \n",
    "\n",
    "    if t%1 == 0:\n",
    "        print('iteration %d / %d: loss %f' % (t, iterations, loss))\n",
    "\n",
    "    # Backward pass\n",
    "    dy_pred=(1./batch_size)*2.0*(y_pred-y)\n",
    "    dw1=x.T.dot(dy_pred)+reg*w1\n",
    "    db1=dy_pred.sum(axis=0)\n",
    "    w1-=lr*dw1\n",
    "    b1-=lr*db1\n",
    "    lr*=lr_decay\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
